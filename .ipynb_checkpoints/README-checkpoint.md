# Module 12 Report

## Overview of the Analysis

In this section, describe the analysis you completed for the machine learning models used in this Challenge. This might include:

The purpose of this analysis is to build a model that can identify the creditworthiness of borrowers. 
We'll use use a dataset of historical lending activity from a peer-to-peer lending services company.
For the target variable, loan_status, there are 75036 healthy loans (label "0") and 2500 high-risk loans (label "1"); meaning we're dealing with imbalanced data. Weâ€™ll use Logistic Regression Model with the Original Data and Logistic Regression Model with Resampled Training Data techniques to train and evaluate models with these imbalanced classes.
The following steps will be undertaken:
* Split the Data into Training and Testing Sets
* Create a Logistic Regression Model with the Original Data
* Predict a Logistic Regression Model with Resampled Training Data

## Results

Using bulleted lists, describe the balanced accuracy scores and the precision and recall scores of all machine learning models.

### Machine Learning Model 1:
  * Our Logistic Regression Model with the Original Data yields an accuracy of 95.2%.
  * It appears all the healthy loans test data were correctly predicted, while just 85% of assigned high-risk loans were actually high risk.
  * With 99% and 91% recall resp. for '0' and '1' labels, the model did well predicting the true positives; with the healthy loans having better recall.



### Machine Learning Model 2:
  * Our Logistic Regression Model with  Resampled Training Data yields an accuracy of 99.4%.
  * There was no change in the precision from the first technique
  * The oversampled data improves the recall for high-risk loans and the specificity for healthy loans

## Summary

Summarize the results of the machine learning models, and include a recommendation on the model to use, if any. For example:
* Which one seems to perform best? How do you know it performs best?    
Overall, resampling improved both the accuracy and the recall. The accuracy improves by a little over 4%, and the recall for high-risk loans improved from 91% to 99%.
* Does performance depend on the problem we are trying to solve? (For example, is it more important to predict the `1`'s, or predict the `0`'s? )   
Yes, the performance is nearly identical if we're predicting "0". But to predict "1", we would use the model with resampled data for a better performance.

* If you do not recommend any of the models, please justify your reasoning.   
With an accuracy of 91% and a precision of 85% on the smaller sample, the model with the original data was already doing well. However, resampling appears to help if we are dealing with a deeper imbalance. 
